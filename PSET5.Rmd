---
title: "Problem Set 5"
author: "Elmer Camargo + Nick Trella"
subtitle: MGSC 310, Fall 2019, Professor Hersh
output:
  word_document: default
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
library(knitr)
# change to your own working directory

knitr::opts_knit$set(root.dir = "C:/Users/Elmer/Documents/R/Statistical Modeling/PSET5")

setwd("C:/Users/Elmer/Documents/R/Statistical Modeling/PSET5")

# set seed 
set.seed(1868)
options(width=70)

# general rchunk code options
opts_chunk$set(tidy.opts=list(width.wrap=50),tidy=TRUE, size = "vsmall")
opts_chunk$set(message = FALSE,
               warning = FALSE,
               cache = TRUE,
               autodep = TRUE,
               cache.comments = FALSE,
               collapse = TRUE,
               fig.width = 5,  
               fig.height = 4,
               fig.align='center')


```

## Libraries Needed

```{r}
library("MASS")
library("tidyverse")
library("plotROC")
```

## Question 1 Derivation of Log Odds Ratio




## Question 2 Predicting Expensive Houses

### a - Preparing Data

```{r}
data(Boston)
set.seed(1861)

trainSize <- 0.75
train_idx <-sample(1:nrow(Boston), size = floor(nrow(Boston)*trainSize))

housing <- Boston %>% mutate(PriceyHome = ifelse(medv > 40, 1,0), chas_factor = factor(chas))

housing_train <- housing%>% slice(train_idx)
housing_test <- housing%>% slice(-train_idx)
```

### b - Where Pricey Homes Differ

```{r}
housing_train <- housing_train %>% group_by(PriceyHome)
sum_train <- housing_train %>% summarise_all(list(mean = mean), na.rm = TRUE)

housing_test <- housing_test %>% group_by(PriceyHome)
sum_test <- housing_test %>% summarise_all(list(mean = mean), na.rm = TRUE)
```

### c - Plots! Plots! Plots!

```{r}
ggplot(housing_train) + geom_point(aes(x = housing_train$zn, y = housing_train$PriceyHome, colour = housing_train$PriceyHome >0), shape = 36, size=6) +
  scale_colour_manual(name = 'PriceyHome', values = setNames(c('green','red'),c(T, F))) +
  xlab('proportion of residential land zoned for lots over 25,000 sq.ft.') + ylab('PriceyHome')

ggplot(housing_train) + geom_point(aes(x = housing_train$age, y = housing_train$PriceyHome, colour = housing_train$PriceyHome >0),size = 2) +
  scale_colour_manual(name = 'PriceyHome', values = setNames(c('green','red'),c(T, F))) +
  xlab('Age') + ylab('PriceyHome')

ggplot(housing_train) + geom_point(aes(x = housing_train$lstat, y = housing_train$PriceyHome, colour = housing_train$PriceyHome >0),size = 2) +
  scale_colour_manual(name = 'PriceyHome', values = setNames(c('green','red'),c(T, F))) +
  xlab('lower status of the population (percent).') + ylab('PriceyHome')
```

Graph One seems to show that for larger homes there seems to be more homes classifed as pricey that are either in small proportioned lands of residential lots or in large ones but not really in the 50th percentile. I believe this would be due to expensive homes being more likely to be in the heart of downtown areas or by itself. Priceyhomes are not likely to appear in the high-density, "cookier cutter" suburbs

Graph Two seems to show that there are more houses at the higher age range classifed as Priceyhomes. Though there are also greater homes classifed as non-Priceyhomes at the upper age range as well and not as many non-Priceyhomes for young homes. This leads me to believe that older houses in particular are where the expensive houses and the cheap houses are. Once they age a lot they are either quite nice or awful.

Graph Three appears to show that PriceyHomes are not present often in areas where there is a greater percentage of lower status people. 
This leads me to the conclusion that in lower status areas (greater than approximately 10%) homes are valued less than they would be otherwise.



### d - Impact of the Charles River

```{r}
log_train_mod = glm(PriceyHome ~ chas,
              data = housing_train,
              family = binomial)

log_test_mod = glm(PriceyHome ~ chas,
                    data = housing_test,
                    family = binomial)
```

The coefficent of 1.5614 on our log model means that if we take the exponential of that number exp(1.5614) = 4.765 we observe an approximately 376% increase in the chance of being a Priceyhome if the home is classifed as chas (if tract bounds river) (at a two star level of significance)

### e - Amenity Impact of the Charles River

```{r}
log_train_mod_plus = glm(PriceyHome ~ chas + crim + lstat + ptratio + zn + rm + rad + nox,
              data = housing_train,
              family = binomial)

log_test_mod_plus = glm(PriceyHome ~ chas + crim + lstat + ptratio + zn + rm + rad + nox,
                         data = housing_test,
                         family = binomial)

summary(log_train_mod_plus)
```

For chas, we can interpret is as again taking the exponetial of it (although we lost p-value significance,meaning that there is a decent chance this value would come about as per chance) but if we take the exponentialwe get exp(0.29088) = 1.3376 which would indicate a 33% higher chance of having  Pricey home if chas=1 (if tract bounds river)

### f - Generating Probability Scores and Class Predictions

```{r}
preds_train_DF <- data.frame(
  scores_train = predict(log_train_mod_plus, 
                         type = "response"),
  housing_train
)

preds_test_DF <- data.frame(
  scores_test = predict(log_test_mod_plus, 
                        type = "response"),
  housing_test
)
```

### g - Classification + Confusion Matrices

```{r}
preds_train_DF <-  preds_train_DF %>% mutate(PosNeg05 = 
                                               ifelse(scores_train > 0.5 & PriceyHome == 1, "TP",
                                               ifelse(scores_train > 0.5 & PriceyHome == 0, "FP",
                                               ifelse(scores_train <= 0.5 & PriceyHome == 0, "TN",
                                               ifelse(scores_train <= 0.5 & PriceyHome == 0, "FN",0)))))

preds_test_DF <-  preds_test_DF %>% mutate(PosNeg05 = 
                                               ifelse(scores_test > 0.5 & PriceyHome == 1, "TP",
                                               ifelse(scores_test > 0.5 & PriceyHome == 0, "FP",
                                               ifelse(scores_test <= 0.5 & PriceyHome == 0, "TN",
                                               ifelse(scores_test <= 0.5 & PriceyHome == 1, "FN",0)))))

preds_train_DF <- data.frame(
  
  class_pred05 = ifelse(preds_train_DF$scores_train
                        > 0.5, 1, 0),
  preds_train_DF
)

preds_test_DF <- data.frame(
  
  class_pred05 = ifelse(preds_test_DF$scores_test
                        > 0.5, 1, 0),
  preds_test_DF
)

table(preds_train_DF$PosNeg05)
table(preds_train_DF$class_pred05,preds_train_DF$PriceyHome)

table(preds_test_DF$PosNeg05)
table(preds_test_DF$class_pred05,preds_test_DF$PriceyHome)
```

### h - Interpretation and Adjustments

true positve rate/sensitivity is good == 76%, we might want to change 19/25 tp/tp+fn

true negative rate/specifity == 99.7% , super good no change 353/354 fn/tn+fp

false positive rate/type 1 error ==  0%, fp/fp+tn 

we should increase the prob cut off (moviong closer to 0) because it should increase our true positive rate at the expense of our false positive rate. Other factors we should consider for changing the cutoff would be what the intention behind our model is If we are only concerned about predicting homes that are not PriceyHomes, we're doing good and could move the cutoff until we no longer are at that 99+ percentage prediction rate. However, if we are more concerned with predicting homes that are actually pricey, we would want to adjust out cutoff until we're I'd argue 90+ percent accurate on predicting them. The trade off is ever present and we should act in according to our best interest here.


### i - ROC Plots

```{r}
trainROC <- ggplot(data = preds_train_DF,
       aes(m = scores_train,
              d = PriceyHome)) +
       geom_roc(labelsize = 3.5,
                cutoffs.at = c(.99,.9,.7,.5,.3,.1,0))

trainROC

testROC <- ggplot(data = preds_test_DF,
       aes(m = scores_test,
              d = PriceyHome)) +
       geom_roc(labelsize = 3.5,
                cutoffs.at = c(.99,.9,.7,.5,.3,.1))

testROC
```


### j - Test of Fitness - Area Under the Curve

```{r}
calc_auc(trainROC)
calc_auc(testROC)
```

The training model is most likely overfit as the area of the curve is nearly one. In order to reduce this overfitting we would reccomended taking out some variables and get more data.

The test model appears decently fit based on the AUC number calculated, leading us to believe that only minor changes would be neccesary to imporve model fit. More data would help though.
